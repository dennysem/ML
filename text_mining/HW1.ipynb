{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./smsspamcollection/SMSSpamCollection.txt', sep='\\t', names=['label','msg'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.msg.values\n",
    "y = data.label.apply(lambda m: 1 if m == 'spam' else 0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer() \n",
    "X_transformed = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9326402983610631"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(), X_transformed, y, scoring='f1', cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0 0 0\n"
     ]
    }
   ],
   "source": [
    "X_test = [\"FreeMsg:\tTxt:\tCALL\tto\tNo:\t86888\t&\tclaim\tyour\treward\tof\t3\thours\ttalk\ttime\tto\tuse\tfrom\tyour\tphone\tnow!\tSubscribe6GB\",\n",
    "\"FreeMsg:\tTxt:\tclaim\tyour\treward\tof\t3\thours\ttalk\ttime\",\n",
    "\"Have\tyou\tvisited\tthe\tlast\tlecture\ton\tphysics?\",\n",
    "\"Have\tyou\tvisited\tthe\tlast\tlecture\ton\tphysics?\tJust\tbuy\tthis\tbook\tand\tyou\twill\thave\tall\tmaterials!\tOnly\t99$\",\n",
    "\"Only\t99$\"]\n",
    "\n",
    "clf = LogisticRegression().fit(X_transformed, y)\n",
    "X_test_transformed = vect.transform(X_test)\n",
    "print ' '.join(map(str, clf.predict(X_test_transformed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 0.73 0.93\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "results.append(cross_val_score(LogisticRegression(), CountVectorizer(ngram_range=(2,2)).fit_transform(X), y, scoring='f1', cv=10).mean())\n",
    "results.append(cross_val_score(LogisticRegression(), CountVectorizer(ngram_range=(3,3)).fit_transform(X), y, scoring='f1', cv=10).mean())\n",
    "results.append(cross_val_score(LogisticRegression(), CountVectorizer(ngram_range=(1,3)).fit_transform(X), y, scoring='f1', cv=10).mean())\n",
    "print ' '.join(map(lambda f: '{0:.2f}'.format(f), results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 0.38 0.89\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "results.append(cross_val_score(MultinomialNB(), CountVectorizer(ngram_range=(2,2)).fit_transform(X), y, scoring='f1', cv=10).mean())\n",
    "results.append(cross_val_score(MultinomialNB(), CountVectorizer(ngram_range=(3,3)).fit_transform(X), y, scoring='f1', cv=10).mean())\n",
    "results.append(cross_val_score(MultinomialNB(), CountVectorizer(ngram_range=(1,3)).fit_transform(X), y, scoring='f1', cv=10).mean())\n",
    "print ' '.join(map(lambda f: '{0:.2f}'.format(f), results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85285995541724557"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LogisticRegression(), TfidfVectorizer().fit_transform(X), y, scoring='f1', cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913447831757\n",
      "{'vect__ngram_range': (1, 1), 'clf__penalty': 'l1', 'vect__binary': True, 'vect__min_df': 0.01, 'vect__max_df': 0.2}\n",
      "CPU times: user 17min 23s, sys: 24.6 s, total: 17min 48s\n",
      "Wall time: 18min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "params_grid = [{\n",
    "        'vect__ngram_range': [(1,1), (1,2), (1,3), (1,4)],\n",
    "        'vect__binary': [True, False],\n",
    "        'vect__min_df': [0.01, 0.03, 0.05],\n",
    "        'vect__max_df': [0.1, 0.15, 0.2],\n",
    "        'clf__penalty': ['l1', 'l2'],\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params_grid, scoring='f1', cv=10)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print grid_search.best_score_\n",
    "print grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935834740277\n",
      "{'vect__ngram_range': (1, 2), 'clf__penalty': 'l2', 'vect__binary': False, 'vect__max_df': 0.2}\n",
      "CPU times: user 2min 49s, sys: 3.07 s, total: 2min 52s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "params_grid = [{\n",
    "        'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "        'vect__binary': [True, False],\n",
    "        'vect__max_df': [0.1, 0.2],\n",
    "        'clf__penalty': ['l1', 'l2']\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params_grid, scoring='f1', cv=10)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print grid_search.best_score_\n",
    "print grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Линейные и байессовские модели неплохо справляются с классификацией текстов\n",
    "\n",
    "2) Tfidf не всегда лучше bag-of-words\n",
    "\n",
    "3) Байессовский классификатор работает лучше при бОльших статистиках\n",
    "\n",
    "4) Не стоит бояться добавлять n-граммы больших размеров"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
